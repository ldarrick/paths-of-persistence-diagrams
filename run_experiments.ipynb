{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Experiments\n",
    "\n",
    "In this notebook, we perform the regression experiments shown in Section 7.5 of the paper \"Signatures, Lipschitz-free spaces, and paths of persistence diagrams\" (C. Giusti and D. Lee).  \n",
    "\n",
    "In this experiment, we generate simulated data from a model of collective motion (the 3D D'Orsogna model), which relies on two parameters $C$ and $\\ell$. For each simulation, we compute persistent homology at each time step, and use the resulting path of persistence diagrams to perform parameter estimation. This is done by computing the Gram matrices and using kernel support vector regression.  \n",
    "\n",
    "The precise steps are as follows.\n",
    "\n",
    "0. **Setup and Parameters**: Create relevant directories and set parameters for the experiment.  \n",
    "\n",
    "1. **Generate Swarm Data**: Solve the differential equations which govern the 3D D'Orsogna model to generate swarms as time-varying point clouds. This only needs to be computed once for all experiments.  \n",
    "\n",
    "2. **Compute (Subsampled) Persistent Homology**: Compute persistent homology for each point cloud to obtain time-varying persistence diagrams. Furthermore, we consider experiments with missing data, where we subsample a collection of agents at each time step. We also compute the time-varying persistence diagrams for these cases.  \n",
    "\n",
    "3. **Compute Features**: We must first apply feature maps to the persistence diagrams. Here, we compute persistence paths and persistence moments. Persistence landscapes and images are computed in the python notebook.  \n",
    "\n",
    "4. **Compute Kernels**: We compute signature kernels for all of the features, applying between 0-2 lags in the sliding window embedding. We also compute the Euclidean kernel for the CROCKER plots.  \n",
    "\n",
    "5. **Perform Regression**: Perform regression while optimizing for hyperparameteres via cross-validation.  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SW_MMD_kernel (generic function with 6 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "using MAT\n",
    "using Statistics\n",
    "include(\"compute_features.jl\")\n",
    "include(\"PathSignatures.jl\")\n",
    "include(\"regression_utils.jl\")\n",
    "include(\"utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need to change these parameters\n",
    "\n",
    "# Agent subsample number (in the paper, we use 200 and 50)\n",
    "ss = 200\n",
    "\n",
    "## Heterogeneous experiments\n",
    "# Only run ss=50/mixed=true after both ss=200/mixed=false and ss=50/mixed=false have been computed\n",
    "mixed = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Int64}:\n",
       " 100\n",
       "  50\n",
       "  20\n",
       "  50\n",
       "  20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Directory names\n",
    "swarm_fpath = \"data/swarm/\" # Directory for the swarm data\n",
    "base_fpath = string(\"data/ss\", ss, \"/\") # Base directory for this experiment\n",
    "temp_subsample = [\"init100/\", \"init50/\", \"init20/\", \"random50/\", \"random20/\"]\n",
    "\n",
    "# Simulation parameters\n",
    "alpha = 1.0 # This is alpha - gamma in the nguyen paper\n",
    "gamma = 1.0\n",
    "beta = 0.5\n",
    "Ca = 1\n",
    "la = 1\n",
    "m = 1\n",
    "N = 200 # Number of agents in one simulation\n",
    "temp = 0.0\n",
    "\n",
    "numT = 100 # Number of time points in simulation\n",
    "numRun = 500 # Number of simulations\n",
    "endT = 200.0 # End time of simulation\n",
    "tspan = (0,endT)\n",
    "trange = range(0, stop=endT, length=numT) # Discrete time points of simulation\n",
    "\n",
    "boundedlimit = 40.0\n",
    "\n",
    "# Log-discretization for scale parameter (for betti curves)\n",
    "tp = 10 .^(range(-4, stop=0, length=100))\n",
    "\n",
    "# Number of temporal subsamples\n",
    "numT_subsample = [100, 50, 20, 50, 20]\n",
    "\n",
    "# Feature and Kernel Parameters\n",
    "moment_level = 2\n",
    "perspath_level = 2\n",
    "signature_level = 3\n",
    "lags = [0,1,2]\n",
    "\n",
    "# Regression parameters\n",
    "num_iterations = 100\n",
    "tr_split = 0.8 # training split\n",
    "hyp_cv = 4 # number of folds in cross-validation to do hyperparameter optimization\n",
    "\n",
    "SVR_C = 10. .^(-3:1:1) # SVR C values to optimize over\n",
    "SVR_eps = 10. .^(-4:1:0) # SVR epsilon values to optimize over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "for tdir in temp_subsample\n",
    "    if ~isdir(string(base_fpath, tdir))\n",
    "        mkdir(string(base_fpath, tdir))\n",
    "    end\n",
    "\n",
    "    PD_fpath = string(base_fpath, tdir, \"PD/\")\n",
    "    FT_fpath = string(base_fpath, tdir, \"FT/\")\n",
    "    KE_fpath = string(base_fpath, tdir, \"KE/\")\n",
    "    RG_fpath = string(base_fpath, tdir, \"RG/\")\n",
    "\n",
    "    if ~isdir(PD_fpath)\n",
    "        mkdir(PD_fpath)\n",
    "    end\n",
    "\n",
    "    if ~isdir(FT_fpath)\n",
    "        mkdir(FT_fpath)\n",
    "    end\n",
    "\n",
    "    if ~isdir(KE_fpath)\n",
    "        mkdir(KE_fpath)\n",
    "    end\n",
    "\n",
    "    if ~isdir(RG_fpath)\n",
    "        mkdir(RG_fpath)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Swarm Data\n",
    "\n",
    "**NOTE**: This only needs to be computed once. All subsequent experiments (with agent or temporal subsampling) is done with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all parameters in a dictionary\n",
    "paramDict = Dict{String, Float64}()\n",
    "paramDict[\"alpha\"] = alpha\n",
    "paramDict[\"beta\"] = beta\n",
    "paramDict[\"Ca\"] = Ca\n",
    "paramDict[\"la\"] = la\n",
    "paramDict[\"m\"] = m\n",
    "paramDict[\"N\"] = N\n",
    "paramDict[\"temp\"] = temp\n",
    "paramDict[\"numT\"] = numT\n",
    "paramDict[\"numRun\"] = numRun\n",
    "paramDict[\"endT\"] = endT\n",
    "paramDict[\"boundedlimit\"] = boundedlimit\n",
    "\n",
    "# Compute everything ######################################\n",
    "PP = Array{Array{Float64, 3},1}(undef, numRun)\n",
    "\n",
    "CL = zeros(numRun,2)\n",
    "\n",
    "for j = 1:numRun\n",
    "    u0 = rand(Uniform(-1,1),6*N)\n",
    "\n",
    "    for i = 1:N\n",
    "        u0[6*(i-1)+4:6*(i-1)+6] = randn(3).+1\n",
    "    end\n",
    "    \n",
    "    cur_maxpos = 100\n",
    "    curP = zeros(3,N,numT)\n",
    "    curV = zeros(3,N,numT)\n",
    "    C=0\n",
    "    l=0\n",
    "    \n",
    "    # Run new simulations until we get a bounded phenotype\n",
    "    while cur_maxpos > boundedlimit\n",
    "        C = rand(Uniform(0.1,2))\n",
    "        l = rand(Uniform(0.1,2))\n",
    "        cur_params = [alpha; beta; C; Ca; l; la; m; N; temp]\n",
    "        prob = ODEProblem(dorsogna3d, u0, tspan, cur_params)\n",
    "        sol = solve(prob)\n",
    "        sol_interp = hcat(sol(trange).u...)\n",
    "\n",
    "        for n = 1:N\n",
    "            curP[1,n,:] = sol_interp[6*(n-1)+1,:]\n",
    "            curP[2,n,:] = sol_interp[6*(n-1)+2,:]\n",
    "            curP[3,n,:] = sol_interp[6*(n-1)+3,:]\n",
    "            curV[1,n,:] = sol_interp[6*(n-1)+4,:]\n",
    "            curV[2,n,:] = sol_interp[6*(n-1)+5,:]\n",
    "            curV[3,n,:] = sol_interp[6*(n-1)+6,:]\n",
    "        end\n",
    "        \n",
    "        cur_maxpos = maximum(abs.(curP[:,:,1:100]))\n",
    "    end\n",
    "    \n",
    "    CL[j,1] = C\n",
    "    CL[j,2] = l\n",
    "    PP[j] = curP\n",
    "    println(string(\"Completed simulation \", j, \"/\", numRun))\n",
    "    sleep(0.1)\n",
    "end\n",
    "\n",
    "# Save swarm simulation data\n",
    "fname = string(swarm_fpath,\"swarm3d_data.mat\")\n",
    "ofile = matopen(fname, \"w\")\n",
    "write(ofile, \"PP\", PP)\n",
    "write(ofile, \"paramDict\", paramDict)\n",
    "close(ofile)\n",
    "\n",
    "fname = string(swarm_fpath,\"CL_data.mat\")\n",
    "ofile = matopen(fname, \"w\")\n",
    "write(ofile, \"CL\", CL)\n",
    "close(ofile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute (Subsampled) Persistent Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute base persistence diagrams (unnormalized)\n",
    "\n",
    "# Load swarm data\n",
    "fname = string(swarm_fpath,\"swarm3d_data.mat\")\n",
    "file = matopen(fname,\"r\")\n",
    "PP = read(file, \"PP\")\n",
    "close(file)\n",
    "\n",
    "# Initialize arrays for (unnormalized) persistence data\n",
    "# B0, B1, B2: persistence diagrams (birth, death)\n",
    "# BE: Betti curve\n",
    "B0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "B1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "B2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "BE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "# Compute unnormalized persistence\n",
    "for j = 1:numRun\n",
    "\n",
    "    # Get current swarm simulation run\n",
    "    curP = PP[j]\n",
    "\n",
    "    # Initialize current arrays for persistence data\n",
    "    curB0 = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    curB1 = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    curB2 = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    curBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    \n",
    "    for t = 1:numT\n",
    "\n",
    "        curP_ss = curP[:,:,t]\n",
    "\n",
    "        # Compute persistence\n",
    "        C = eirene(curP_ss, model=\"pc\", maxdim=2)\n",
    "        curB0[t] = barcode(C, dim=0)\n",
    "        curB0[t] = curB0[t][1:end-1,:]\n",
    "        curB1[t] = barcode(C, dim=1)\n",
    "        curB2[t] = barcode(C, dim=2)\n",
    "        \n",
    "        # Compute Betti curves\n",
    "        curB = [curB0[t], curB1[t], curB2[t]]\n",
    "        curBE[t] = betti_embedding(curB, tp)\n",
    "    end\n",
    "\n",
    "    B0[j] = curB0\n",
    "    B1[j] = curB1\n",
    "    B2[j] = curB2\n",
    "    BE[j] = curBE\n",
    "end\n",
    "\n",
    "# Write data\n",
    "ofname = string(PD_fpath, temp_subsample[1], \"PD.mat\")\n",
    "ofile = matopen(ofname, \"w\")\n",
    "write(ofile, \"B0\", B0)\n",
    "write(ofile, \"B1\", B1)\n",
    "write(ofile, \"B2\", B2)\n",
    "write(ofile, \"BE\", BE)\n",
    "close(ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read base persistence diagram\n",
    "file = matopen(\"data/ss200/PD/PD.mat\",\"r\")\n",
    "B0 = read(file, \"B0\")\n",
    "B1 = read(file, \"B1\")\n",
    "B2 = read(file, \"B2\")\n",
    "BE = read(file, \"BE\")\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate persistence diagrams for all temporal subsamples\n",
    "# Also compute the normalized persistence diagrams for the mixed case\n",
    "\n",
    "# Scaling factor (relative to total = 200 points)\n",
    "sf = ss/float(N)\n",
    "\n",
    "# initial100 ################################################\n",
    "nB0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "nB1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nB2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nNBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "numT = 100\n",
    "for i = 1:numRun\n",
    "    nB0[i] = B0[i][1:numT]\n",
    "    nB1[i] = B1[i][1:numT]\n",
    "    nB2[i] = B2[i][1:numT]\n",
    "    nBE[i] = BE[i][1:numT]\n",
    "end\n",
    "\n",
    "# Generate normalized BE\n",
    "for i = 1:numRun\n",
    "    curNBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    for t = 1:numT\n",
    "        curB = [nB0[i][t], nB1[i][t], nB2[i][t]]\n",
    "        curNBE[t] = betti_embedding(curB.*(sf^(1/3)), tp)/sf\n",
    "    end\n",
    "    nNBE[i] = curNBE\n",
    "end\n",
    "\n",
    "PD_fname = string(base_fpath, \"init100/\", \"PD/PD.mat\")\n",
    "file = matopen(PD_fname, \"w\")\n",
    "write(file, \"B0\", nB0)\n",
    "write(file, \"B1\", nB1)\n",
    "write(file, \"B2\", nB2)\n",
    "write(file, \"BE\", nBE)\n",
    "write(file, \"NBE\", nNBE)\n",
    "close(file)\n",
    "\n",
    "PDG_fname = string(base_fpath, \"init100/\", \"PD/PDG.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDG_fname,1,100)\n",
    "PDGN_fname = string(base_fpath, \"init100/\", \"PD/PDGN.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDGN_fname,1,100,sf)\n",
    "\n",
    "# initial50 #################################################\n",
    "nB0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "nB1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nB2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nNBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "numT = 50\n",
    "for i = 1:numRun\n",
    "    nB0[i] = B0[i][1:numT]\n",
    "    nB1[i] = B1[i][1:numT]\n",
    "    nB2[i] = B2[i][1:numT]\n",
    "    nBE[i] = BE[i][1:numT]\n",
    "end\n",
    "\n",
    "# Generate normalized BE\n",
    "for i = 1:numRun\n",
    "    curNBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    for t = 1:numT\n",
    "        curB = [nB0[i][t], nB1[i][t], nB2[i][t]]\n",
    "        curNBE[t] = betti_embedding(curB.*(sf^(1/3)), tp)/sf\n",
    "    end\n",
    "    nNBE[i] = curNBE\n",
    "end\n",
    "\n",
    "PD_fname = string(base_fpath, \"init50/\", \"PD/PD.mat\")\n",
    "file = matopen(PD_fname, \"w\")\n",
    "write(file, \"B0\", nB0)\n",
    "write(file, \"B1\", nB1)\n",
    "write(file, \"B2\", nB2)\n",
    "write(file, \"BE\", nBE)\n",
    "write(file, \"NBE\", nNBE)\n",
    "close(file)\n",
    "\n",
    "PDG_fname = string(base_fpath, \"init50/\", \"PD/PDG.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDG_fname,1,50)\n",
    "PDGN_fname = string(base_fpath, \"init50/\", \"PD/PDGN.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDGN_fname,1,50,sf)\n",
    "\n",
    "\n",
    "# initial20 #################################################\n",
    "nB0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "nB1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nB2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nNBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "numT = 20\n",
    "for i = 1:numRun\n",
    "    nB0[i] = B0[i][1:numT]\n",
    "    nB1[i] = B1[i][1:numT]\n",
    "    nB2[i] = B2[i][1:numT]\n",
    "    nBE[i] = BE[i][1:numT]\n",
    "end\n",
    "\n",
    "# Generate normalized BE\n",
    "for i = 1:numRun\n",
    "    curNBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    for t = 1:numT\n",
    "        curB = [nB0[i][t], nB1[i][t], nB2[i][t]]\n",
    "        curNBE[t] = betti_embedding(curB.*(sf^(1/3)), tp)/sf\n",
    "    end\n",
    "    nNBE[i] = curNBE\n",
    "end\n",
    "\n",
    "PD_fname = string(base_fpath, \"init20/\", \"PD/PD.mat\")\n",
    "file = matopen(PD_fname, \"w\")\n",
    "write(file, \"B0\", nB0)\n",
    "write(file, \"B1\", nB1)\n",
    "write(file, \"B2\", nB2)\n",
    "write(file, \"BE\", nBE)\n",
    "write(file, \"NBE\", nNBE)\n",
    "close(file)\n",
    "\n",
    "PDG_fname = string(base_fpath, \"init20/\", \"PD/PDG.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDG_fname,1,20)\n",
    "PDGN_fname = string(base_fpath, \"init20/\", \"PD/PDGN.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDGN_fname,1,20,sf)\n",
    "\n",
    "\n",
    "# random50 #################################################\n",
    "nB0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "nB1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nB2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nNBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "numT = 50\n",
    "for i = 1:numRun\n",
    "    subTP = sort(randperm(MersenneTwister(i),100)[1:numT])\n",
    "    nB0[i] = B0[i][subTP]\n",
    "    nB1[i] = B1[i][subTP]\n",
    "    nB2[i] = B2[i][subTP]\n",
    "    nBE[i] = BE[i][subTP]\n",
    "end\n",
    "\n",
    "# Generate normalized BE\n",
    "for i = 1:numRun\n",
    "    curNBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    for t = 1:numT\n",
    "        curB = [nB0[i][t], nB1[i][t], nB2[i][t]]\n",
    "        curNBE[t] = betti_embedding(curB.*(sf^(1/3)), tp)/sf\n",
    "    end\n",
    "    nNBE[i] = curNBE\n",
    "end\n",
    "\n",
    "PD_fname = string(base_fpath, \"random50/\", \"PD/PD.mat\")\n",
    "file = matopen(PD_fname, \"w\")\n",
    "write(file, \"B0\", nB0)\n",
    "write(file, \"B1\", nB1)\n",
    "write(file, \"B2\", nB2)\n",
    "write(file, \"BE\", nBE)\n",
    "write(file, \"NBE\", nNBE)\n",
    "close(file)\n",
    "\n",
    "PDG_fname = string(base_fpath, \"random50/\", \"PD/PDG.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDG_fname,1,50)\n",
    "PDGN_fname = string(base_fpath, \"random50/\", \"PD/PDGN.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDGN_fname,1,50, sf)\n",
    "\n",
    "\n",
    "# random20 #################################################\n",
    "nB0 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun) \n",
    "nB1 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nB2 = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "nNBE = Array{Array{Array{Float64, 2}, 1},1}(undef, numRun)\n",
    "\n",
    "numT = 20\n",
    "for i = 1:numRun\n",
    "    subTP = sort(randperm(MersenneTwister(i),100)[1:numT])\n",
    "    nB0[i] = B0[i][subTP]\n",
    "    nB1[i] = B1[i][subTP]\n",
    "    nB2[i] = B2[i][subTP]\n",
    "    nBE[i] = BE[i][subTP]\n",
    "end\n",
    "\n",
    "# Generate normalized BE\n",
    "for i = 1:numRun\n",
    "    curNBE = Array{Array{Float64, 2},1}(undef, numT)\n",
    "    for t = 1:numT\n",
    "        curB = [nB0[i][t], nB1[i][t], nB2[i][t]]\n",
    "        curNBE[t] = betti_embedding(curB.*(sf^(1/3)), tp)/sf\n",
    "    end\n",
    "    nNBE[i] = curNBE\n",
    "end\n",
    "\n",
    "PD_fname = string(base_fpath, \"random20/\", \"PD/PD.mat\")\n",
    "file = matopen(PD_fname, \"w\")\n",
    "write(file, \"B0\", nB0)\n",
    "write(file, \"B1\", nB1)\n",
    "write(file, \"B2\", nB2)\n",
    "write(file, \"BE\", nBE)\n",
    "write(file, \"NBE\", nNBE)\n",
    "close(file)\n",
    "\n",
    "PDG_fname = string(base_fpath, \"random20/\", \"PD/PDG.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDG_fname,1,20)\n",
    "PDGN_fname = string(base_fpath, \"random20/\", \"PD/PDGN.mat\")\n",
    "pd_to_giotto_mat(PD_fname, PDGN_fname,1,20,sf)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Julia Features (Moments and PersPath)\n",
    "\n",
    "Compute the python features from the other notebook before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tdir in temp_subsample\n",
    "    PD_fpath = string(base_fpath, tdir, \"PD/\")\n",
    "    FT_fpath = string(base_fpath, tdir, \"FT/\")\n",
    "\n",
    "    file = matopen(string(PD_fpath, \"PD.mat\"), \"r\")\n",
    "    B0 = read(file, \"B0\")\n",
    "    B1 = read(file, \"B1\")\n",
    "    B2 = read(file, \"B2\")\n",
    "    BE = read(file, \"BE\")\n",
    "    close(file)\n",
    "\n",
    "    compute_PD_moments(B0, B1, B2, moment_level, FT_fpath)\n",
    "    compute_PD_perspath(BE, perspath_level, FT_fpath)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tdir in temp_subsample\n",
    "\n",
    "    FT_fpath = string(base_fpath, tdir, \"FT/\")\n",
    "    KE_fpath = string(base_fpath, tdir, \"KE/\")\n",
    "    all_feat = readdir(FT_fpath)\n",
    "    numfeat = length(all_feat)\n",
    "\n",
    "    for i = 1:numfeat\n",
    "        cur_feat = all_feat[i]\n",
    "        feat_name = split(cur_feat,\".\")[1]\n",
    "        feat_type = split(cur_feat,\"_\")[1]\n",
    "\n",
    "        file = matopen(string(FT_fpath, cur_feat),\"r\")\n",
    "        FT = read(file, \"FT\")\n",
    "        close(file)\n",
    "\n",
    "        if feat_type == \"PL\" || feat_type == \"LPL\" || feat_type == \"PI\" || feat_type == \"LPI\"\n",
    "            numRun = size(FT)[1]\n",
    "            \n",
    "            FTrs = Array{Array{Float64, 2}, 1}(undef, numRun)\n",
    "            for j = 1:numRun\n",
    "                FTrs[j] = FT[j,:,:]\n",
    "            end\n",
    "            \n",
    "            FT = FTrs\n",
    "        end\n",
    "\n",
    "        numT = size(FT[1])[1]\n",
    "        numC = size(FT[1])[2]\n",
    "\n",
    "        for l in lags\n",
    "            lagp = l+1\n",
    "            # Add lags\n",
    "            FT_lag = Array{Array{Float64, 2}, 1}(undef, numRun)\n",
    "            for i = 1:numRun\n",
    "                curFT = zeros(numT, numC*lagp)\n",
    "\n",
    "                for l = 1:lagp\n",
    "                    curFT[l:end, (l-1)*numC+1:l*numC] = FT[i][1:end-(l-1),:]\n",
    "                end\n",
    "\n",
    "                FT_lag[i] = curFT\n",
    "            end\n",
    "\n",
    "            K = dsignature_kernel_matrix(FT_lag, [], signature_level, \"R\")\n",
    "\n",
    "            fname = string(KE_fpath, feat_name, \"_S\", signature_level, \"_L\", l, \".mat\")\n",
    "            file = matopen(fname, \"w\")\n",
    "            write(file, \"K\", K)\n",
    "            close(file)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CROCKER\n",
    "\n",
    "numT_CRKR = 20 # number of time points in crocker plot\n",
    "numE = 100 # number of epsilon points in betti curve\n",
    "\n",
    "numdim_CRKR = numT_CRKR*numE*3\n",
    "ndim_block = numE*3\n",
    "\n",
    "for (t_ind, tdir) in enumerate(temp_subsample)\n",
    "    numT = numT_subsample[t_ind]\n",
    "    PD_fpath = string(base_fpath, tdir, \"PD/PD.mat\")\n",
    "    KE_fpath = string(base_fpath, tdir, \"KE/\")\n",
    "\n",
    "    file = matopen(PD_fpath, \"r\")\n",
    "    BE = read(file, \"BE\")\n",
    "    close(file)\n",
    "\n",
    "    # Further subsample the time axis to reduce dimensionality\n",
    "    tp_CRKR = Int.(round.(collect(range(numT/numT_CRKR, stop=numT ,length=numT_CRKR))))\n",
    "\n",
    "    CRKR = zeros(numRun, numdim_CRKR)\n",
    "\n",
    "    for i = 1:numRun\n",
    "        for t = 1:numT_CRKR\n",
    "            CRKR[i,(t-1)*ndim_block+1:t*ndim_block] = BE[i][tp_CRKR[t]][:]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    K = zeros(numRun, numRun)\n",
    "\n",
    "    for i = 1:numRun\n",
    "        for j = i:numRun\n",
    "            K[i,j] = dot(CRKR[i,:], CRKR[j,:])\n",
    "            \n",
    "            if i!=j\n",
    "                K[j,i] = K[i,j]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    fname = string(KE_fpath, \"CRKR.mat\")\n",
    "    file = matopen(fname, \"w\")\n",
    "    write(file, \"K\", K)\n",
    "    close(file)\n",
    "end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Regression\n",
    "\n",
    "Regression output stored in RG_fpath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing data/ss200/init100/RG/LPI_03_10.mat\n",
      "Computing data/ss200/init100/RG/LPL_5_10.mat\n",
      "Computing data/ss200/init100/RG/MO_2.mat\n",
      "Computing data/ss200/init100/RG/PA_2.mat\n",
      "Computing data/ss200/init100/RG/CRKR.mat\n",
      "Computing data/ss200/init50/RG/LPI_03_10.mat\n",
      "Computing data/ss200/init50/RG/LPL_5_10.mat\n",
      "Computing data/ss200/init50/RG/MO_2.mat\n",
      "Computing data/ss200/init50/RG/PA_2.mat\n",
      "Computing data/ss200/init50/RG/CRKR.mat\n",
      "Computing data/ss200/init20/RG/LPI_03_10.mat\n",
      "Computing data/ss200/init20/RG/LPL_5_10.mat\n",
      "Computing data/ss200/init20/RG/MO_2.mat\n",
      "Computing data/ss200/init20/RG/PA_2.mat\n",
      "Computing data/ss200/init20/RG/CRKR.mat\n",
      "Computing data/ss200/random50/RG/LPI_03_10.mat\n",
      "Computing data/ss200/random50/RG/LPL_5_10.mat\n",
      "Computing data/ss200/random50/RG/MO_2.mat\n",
      "Computing data/ss200/random50/RG/PA_2.mat\n",
      "Computing data/ss200/random50/RG/CRKR.mat\n",
      "Computing data/ss200/random20/RG/LPI_03_10.mat\n",
      "Computing data/ss200/random20/RG/LPL_5_10.mat\n",
      "Computing data/ss200/random20/RG/MO_2.mat\n",
      "Computing data/ss200/random20/RG/PA_2.mat\n",
      "Computing data/ss200/random20/RG/CRKR.mat\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter search over lags too\n",
    "\n",
    "num_iterations = 100\n",
    "tr_split = 0.8\n",
    "hyp_cv = 4\n",
    "\n",
    "SVR_C = 10. .^(-3:1:1)\n",
    "SVR_eps = 10. .^(-4:1:0)\n",
    "\n",
    "file = matopen(\"CL_data.mat\", \"r\")\n",
    "CL = read(file, \"CL\")\n",
    "close(file)\n",
    "\n",
    "all_reg_mean = []\n",
    "all_reg_std = []\n",
    "\n",
    "for tdir in temp_subsample\n",
    "    FT_fpath = string(base_fpath, tdir, \"FT/\")\n",
    "    KE_fpath = string(base_fpath, tdir, \"KE/\")\n",
    "    RG_fpath = string(base_fpath, tdir, \"RG/\")\n",
    "\n",
    "    all_K = readdir(FT_fpath)\n",
    "    push!(all_K, \"CRKR.mat\")\n",
    "    numK = length(all_K)\n",
    "\n",
    "    reg_mean = zeros(numK,2)\n",
    "    reg_std = zeros(numK, 2)\n",
    "\n",
    "    for i = 1:numK\n",
    "        cur_K = all_K[i]\n",
    "        K_name = split(cur_K,\".\")[1]\n",
    "        RG_fname = string(RG_fpath, cur_K)\n",
    "\n",
    "        if isfile(RG_fname)\n",
    "            file = matopen(RG_fname, \"r\")\n",
    "            reg_error = read(file, \"reg_error\")\n",
    "            close(file)\n",
    "\n",
    "            reg_mean[i,:] = mean(reg_error, dims=1)\n",
    "            reg_std[i,:] = std(reg_error, dims=1)\n",
    "            println(string(\"Loading \", RG_fname))\n",
    "        else\n",
    "            println(string(\"Computing \", RG_fname))\n",
    "            if cur_K == \"CRKR.mat\"\n",
    "                file = matopen(string(KE_fpath, cur_K),\"r\")\n",
    "                K = read(file, \"K\")\n",
    "                close(file)\n",
    "\n",
    "                reg_error, SVR_params = run_regression(K, K, CL, num_iterations, SVR_C, SVR_eps, hyp_cv, tr_split)\n",
    "            else\n",
    "                K_all = []\n",
    "                for l = 0:2\n",
    "                    file = matopen(string(KE_fpath, K_name, \"_S3_L\", l, \".mat\"),\"r\")\n",
    "                    K = read(file, \"K\")\n",
    "                    close(file)\n",
    "                    push!(K_all, K)\n",
    "                end\n",
    "\n",
    "                reg_error, SVR_params = run_regression_multikernel(K_all, K_all, CL, num_iterations, SVR_C, SVR_eps, hyp_cv, tr_split)\n",
    "            end\n",
    "            \n",
    "            fname = string(RG_fpath, cur_K)\n",
    "            file = matopen(fname, \"w\")\n",
    "            write(file, \"reg_error\", reg_error)\n",
    "            write(file, \"SVR_params\", SVR_params)\n",
    "            close(file)\n",
    "\n",
    "            reg_mean[i,:] = mean(reg_error, dims=1)\n",
    "            reg_std[i,:] = std(reg_error, dims=1)\n",
    "        end\n",
    "    end\n",
    "    push!(all_reg_mean, reg_mean)\n",
    "    push!(all_reg_std, reg_std)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Matrix{Float64}:\n",
       " 0.0225656  0.124158\n",
       " 0.0333622  0.123827\n",
       " 0.0282311  0.130941\n",
       " 0.0607225  0.215561\n",
       " 0.0324322  0.219933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reg_mean[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zeros(10)\n",
    "Threads.@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 2.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       " 6.0\n",
       " 7.0\n",
       " 8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPL_5_10,   C_error:0.02458420551062546, L_error:0.08149808239342182\n",
      "MO_2,   C_error:0.024838049571270827, L_error:0.08085823014395054\n",
      "PA_2,   C_error:0.09452111284562253, L_error:0.29750533532264667\n",
      "PI_03_10,   C_error:0.04370785941538185, L_error:0.181028121194321\n",
      "PL_5_10,   C_error:0.04607732944341657, L_error:0.23588418408982967\n"
     ]
    }
   ],
   "source": [
    "for i = 1:numK\n",
    "    cur_K = all_K[i]\n",
    "    K_name = split(cur_K,\".\")[1]\n",
    "\n",
    "    println(string(K_name, \",   C_error:\", reg_mean[i,1], \", L_error:\", reg_mean[i,2]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    }
   ],
   "source": [
    "B = 123\n",
    "\n",
    "if B == 123\n",
    "    testingzzzz = 1\n",
    "end\n",
    "print(testingzzzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "File \"newKE_data/MMDK_din_2_40.mat\" does not exist and create was not specified",
     "output_type": "error",
     "traceback": [
      "File \"newKE_data/MMDK_din_2_40.mat\" does not exist and create was not specified\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base ./error.jl:33\n",
      " [2] matopen(filename::String, rd::Bool, wr::Bool, cr::Bool, tr::Bool, ff::Bool, compress::Bool)\n",
      "   @ MAT ~/.julia/packages/MAT/5SDtD/src/MAT.jl:44\n",
      " [3] matopen(fname::String, mode::String; compress::Bool)\n",
      "   @ MAT ~/.julia/packages/MAT/5SDtD/src/MAT.jl:88\n",
      " [4] matopen(fname::String, mode::String)\n",
      "   @ MAT ~/.julia/packages/MAT/5SDtD/src/MAT.jl:88\n",
      " [5] top-level scope\n",
      "   @ ~/projects/swarm/clean_230503/orig_compute_features_jl.ipynb:1"
     ]
    }
   ],
   "source": [
    "file = matopen(\"newKE_data/MMDK_din_2_40.mat\",\"r\")\n",
    "K = read(file, \"K\")\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.039116456762955595 0.21608558333665737; 0.04215830541442393 0.22462702848163926; … ; 0.04403836321256742 0.19304064623443418; 0.04987211994637922 0.229374195557993], [10.0 10.0; 10.0 10.0; … ; 10.0 10.0; 10.0 10.0;;; 0.0001 0.0001; 0.0001 0.0001; … ; 0.0001 0.0001; 0.0001 0.0001])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mreg_error, MSVR_params = run_regression(K, K, CL, 100, SVR_C, SVR_eps, 4, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 0.0379933  0.210309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Mreg_error, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 0.00435456  0.0217293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std(Mreg_error,dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = matopen(\"data/orig/SWD/D_2_40.mat\",\"r\")\n",
    "D = read(file, \"D\")\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = [0.1, 0.5, 1.0]\n",
    "sigma2 = [0.1, 0.5, 1.0]\n",
    "\n",
    "Mreg_mean = zeros(3,3,2)\n",
    "Mreg_std = zeros(3,3,2)\n",
    "\n",
    "for i = 1:3\n",
    "    for j = 1:3\n",
    "        MMDK = compute_MMD(D,sigma1[i], sigma2[j])\n",
    "        Mreg_error, MSVR_params = run_regression(MMDK, MMDK, CL, 100, SVR_C, SVR_eps, 4, 0.8)\n",
    "        Mreg_mean[i,j,:] = mean(Mreg_error, dims=1)\n",
    "        Mreg_std[i,j,:] = std(Mreg_error, dims=1)\n",
    "    end\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.11596407263147249\n",
       " 0.11442928263127414\n",
       " 0.1151486201256615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mreg_mean[3,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×500 Matrix{Float64}:\n",
       " 1.0       0.92683   0.620336  0.696988  …  0.643218  0.936368  0.750345\n",
       " 0.92683   1.0       0.6278    0.705374     0.650957  0.935185  0.759373\n",
       " 0.620336  0.6278    1.0       0.888658     0.874823  0.62544   0.592214\n",
       " 0.696988  0.705374  0.888658  1.0          0.898292  0.702722  0.690527\n",
       " 0.926922  0.952024  0.627777  0.705348     0.650933  0.935884  0.759345\n",
       " 0.873491  0.883685  0.591529  0.664622  …  0.61335   0.880793  0.715528\n",
       " 0.949004  0.931392  0.623293  0.70031      0.646284  0.947051  0.753922\n",
       " 0.851547  0.861792  0.681971  0.778172     0.720929  0.858553  0.803131\n",
       " 0.625173  0.632695  0.992716  0.888859     0.880392  0.630317  0.596576\n",
       " 0.693809  0.702157  0.592486  0.697218     0.667823  0.699517  0.795403\n",
       " ⋮                                       ⋱                      \n",
       " 0.767846  0.777084  0.531655  0.600524     0.555678  0.774164  0.727262\n",
       " 0.694099  0.702449  0.517279  0.591863     0.554393  0.699809  0.810719\n",
       " 0.654023  0.661892  0.646486  0.741041     0.744964  0.659404  0.695427\n",
       " 0.834578  0.844292  0.565242  0.635109     0.586123  0.841265  0.684302\n",
       " 0.955993  0.922369  0.61736   0.693644  …  0.640132  0.931943  0.746745\n",
       " 0.926118  0.953378  0.627346  0.704863     0.650486  0.934316  0.758823\n",
       " 0.643218  0.650957  0.874823  0.898292     1.0       0.64851   0.642566\n",
       " 0.936368  0.935185  0.62544   0.702722     0.64851   1.0       0.756519\n",
       " 0.750345  0.759373  0.592214  0.690527     0.642566  0.756519  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MMDK = compute_MMD(D,1.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0276294665407228 0.11350724821960761; 0.025874362953882776 0.12339223208949657; … ; 0.0258865851184854 0.11814825917361532; 0.03010687683282638 0.12291254346866592], [10.0 10.0; 10.0 10.0; … ; 10.0 10.0; 10.0 10.0;;; 0.1 0.01; 0.01 0.0001; … ; 0.001 0.01; 0.0001 0.01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mreg_error, MSVR_params = run_regression(MMDK, MMDK, CL, 100, SVR_C, SVR_eps, 4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 0.0269334  0.118519"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Mreg_error, dims=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
