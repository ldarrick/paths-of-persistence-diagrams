{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarm Model Regression\n",
    "\n",
    "This notebook provides a walkthrough of all the code used to perform the experiments in the article \"Signatures, Lipschitz-free spaces, and paths of persistence diagrams\" by Chad Giusti and Darrick Lee.  \n",
    "\n",
    "All code for computing path signatures is in `PathSignatures.jl` and all other code is in `swarm_computations.jl`.  \n",
    "\n",
    "The code is structured into 5 parts, where the output is saved at each step.\n",
    "1. **Swarm Simulation**: 500 trials of the 3D D'Orsogna model at various $C$ and $\\ell$ parameters are simulated.\n",
    "2. **Persistent Homology**: Persistent homology is computed at every time step for each simulation. Furthermore, we compute the persistence diagrams for the agent-wise subsampled experiments.\n",
    "3. **Compute Features**: Feature maps (moment map and persistence paths) for the persistence diagrams are computed at every time step.\n",
    "4. **Compute Kernels**: The kernel matrices between the trials are all precomputed.\n",
    "5. **Perform Regression**: Regression is performed using support vector regression with the precomputed kernel matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "swarm_regression (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"swarm_computations.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Swarm Simulation\n",
    "\n",
    "The `swarm_simulate_3d()` function generates 500 trials of the 3D D'Orsogna model at $C, \\ell \\in [0.1, 2]$ chosen uniformly at random. Because we focus on bounded phenotypes, we reject any trial in which any agent moves further than 40.0 units in any direction after $t=200$.  \n",
    "\n",
    "The parameters we use correspond to those used in *Thermal and athermal three-dimensional swarms of self-propelled particles* (Nguyen et al., Physical Review E, 2012). In particular,\n",
    "- $\\alpha = 1.0$: propulsion strength\n",
    "- $\\beta = 0.5$: drag\n",
    "- $m = 1$: mass\n",
    "- $N = 200$: number of agents\n",
    "\n",
    "Our simulation is run up until $T=400.0$, and discretized using 200 uniformly spaced time points.  \n",
    "\n",
    "Output: \n",
    "- `PP`: position data of each agent at every time step for all trials\n",
    "\n",
    "Output folder:  `./SW_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_simulate_3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Persistent Homology\n",
    "\n",
    "We use the `Eirene` package to compute persistent homology at every time step up to dimension 2.  \n",
    "\n",
    "The argument to the `swarm_compute_persistence()` function is the number of agents to subsample independently and uniformly at each time step.  \n",
    "\n",
    "Output:\n",
    "- `B0, B1, B2`: persistence diagrams for each trial and each time point\n",
    "- `BE`: Betti curve for each trial and time point\n",
    "- `NBE`: normalized Betti curve (see Section 6.4 in paper) for each trial and time point\n",
    "\n",
    "Output folder:  `./PD_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_compute_persistence(200)\n",
    "swarm_compute_persistence(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute Features\n",
    "\n",
    "We precompute the feature maps (moment map and persistence paths) for all persistence diagrams using the function `swarm_compute_features()`. The argument to this function is the number of agents to subsample, and the corresponding persistence diagrams from the previous step are used.  \n",
    "\n",
    "The moment map is truncated at level 6, while the path signature of the Betti curves are computed up to level 5. This initial computation is done at higher truncation levels, so that later steps can simply use a subset of these features for lower truncation levels. Normalized features (as in Section 6.4 in the paper) are also computed.  \n",
    "\n",
    "Output:\n",
    "- `MO_F, NMO_F`: moment map and normalized moment map features\n",
    "- `PP_F, NPP_F`: persistence paths and normalized persistence paths features  \n",
    "\n",
    "\n",
    "Output folder:  `./FT_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_compute_features(200)\n",
    "swarm_compute_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute Kernels\n",
    "\n",
    "The kernel matrix is precomputed for every experiment to speed up the kernel regression done in the next step. In particular, we compute $K$, a 500 x 500 matrix, where $$K_{i,j} = \\langle S(X_i), S(X_j)\\rangle,$$ where $X_i$ is the path of features (either moment or perspath) for the $i^{th}$ trial. We also precompute the kernel matrix for the crocker plots, where in this case we have $$K_{i,j} = \\langle BE_i, BE_j\\rangle,$$ where $BE_i$ is the discretized Betti curves (up to dimension 2) of the $i^{th}$ trial.  \n",
    "\n",
    "Arguments:\n",
    "- `ktype`: type of kernel\n",
    "    - `ktype=1`: signature + moment map\n",
    "    - `ktype=2`: signature + perspath\n",
    "    - `ktype=3`: crocker plots\n",
    "- `ss`: number of agents to subsample\n",
    "- `st`: number of time points to subsample\n",
    "- `st_type`: type of temporal subsampling\n",
    "    - `st_type=0`: no temporal subsampling\n",
    "    - `st_type=1`: random temporal subsampling\n",
    "    - `st_type=2`: initial temporal subsampling\n",
    "- `normalized`: set to `true` to use normalized features\n",
    "- `lag`: number of lags for the outer signature features\n",
    "- `in_lvl`: inner truncation level (for moment map or perspath)\n",
    "- `out_lvl`: outer truncation level (for outer path signature of features)\n",
    "- `mixed`: compute the kernel matrix for the heterogeneous experiments\n",
    "\n",
    "Note that `lag`, `in_lvl`, and `out_lvl` are not used for the crocker plot kernel (`ktype=3`)  \n",
    "\n",
    "Output:\n",
    "- `K`: 500 x 500 kernel matrix\n",
    "\n",
    "Output folder:  `./KE_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIRST COLUMN - NO AGENT SUBSAMPLING\n",
    "ss = 200\n",
    "normalized = false\n",
    "mixed = false\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_kernel(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_kernel(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_kernel(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_kernel(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_kernel(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_kernel(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n",
    "\n",
    "## SECOND COLUMN - RANDOM AGENT SUBSAMPLING (N=50)\n",
    "ss = 50\n",
    "normalized = false\n",
    "mixed = false\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_kernel(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_kernel(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_kernel(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_kernel(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_kernel(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_kernel(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "## THIRD COLUMN - RANDOM AGENT SUBSAMPLING (N=50) HETEROGENEOUS TRAIN/TEST\n",
    "ss = 50\n",
    "normalized = true\n",
    "mixed = true\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_kernel(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_kernel(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_kernel(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_kernel(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_kernel(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_kernel(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute Regression\n",
    "\n",
    "We use kernel support vector regression (SVR) to perform regression against the $C$ and $\\ell$ parameters of the model.\n",
    "\n",
    "#### Setup\n",
    "We use a 80/20 train/test split, and we perform 100 iterations by shuffling the splits. The same shuffling is used across all experiments.\n",
    "\n",
    "#### Hyperparameter Selection\n",
    "There are two hyperparameters for SVR: $C_{SVR}$ and $\\epsilon_{SVR}$. These hyperparameters are chosen by a grid search in $C_{SVR} \\in [10^{-3}, 10^3]$ and $\\epsilon_{SVR} \\in [10^{-5}, 10^1]$ on a log scale with 13 points for each parameter. These are chosen by performing 4-fold cross-validatione exclusively on the training data. This hyperparameter selection is repeated for each iteration.  \n",
    "\n",
    "#### Regression Results\n",
    "The mean squared error (MSE) for both $C$ and $\\ell$ are reported for each iteration.  \n",
    "\n",
    "Output:\n",
    "-`K_error`: MSE for all iterations\n",
    "\n",
    "Output folder:  `./RG_data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIRST COLUMN - NO AGENT SUBSAMPLING\n",
    "ss = 200\n",
    "normalized = false\n",
    "mixed = false\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_regression(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_regression(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_regression(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_regression(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_regression(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_regression(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n",
    "\n",
    "## SECOND COLUMN - RANDOM AGENT SUBSAMPLING (N=50)\n",
    "ss = 50\n",
    "normalized = false\n",
    "mixed = false\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_regression(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_regression(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_regression(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_regression(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_regression(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_regression(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "## THIRD COLUMN - RANDOM AGENT SUBSAMPLING (N=50) HETEROGENEOUS TRAIN/TEST\n",
    "ss = 50\n",
    "normalized = true\n",
    "mixed = true\n",
    "in_lvl = 2\n",
    "out_lvl = 3\n",
    "\n",
    "for lag = 0:2\n",
    "    swarm_compute_regression(1, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "    swarm_compute_regression(2, ss, 200, 0, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "end\n",
    "swarm_compute_regression(3, ss, 200, 0, normalized, 0, 0, 0, mixed)\n",
    "\n",
    "for st_type = 1:2\n",
    "    for st = [50, 20]\n",
    "        for lag = 0:2\n",
    "            swarm_compute_regression(1, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "            swarm_compute_regression(2, ss, st, st_type, normalized, lag, in_lvl, out_lvl, mixed)\n",
    "        end\n",
    "        swarm_compute_regression(3, ss, st, st_type, normalized, 0, 0, 0, mixed)\n",
    "    end\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
